{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "OOktbwn1l9R0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"myAPP\").getOrCreate()"
      ],
      "metadata": {
        "id": "u_x6mH5mmDn8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raw Data"
      ],
      "metadata": {
        "id": "v97NfsnS0M-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_data = [\n",
        "    (\"ORD001\",\"C001\",\"Delhi \",\"Electronics\",\"Laptop\",\"45000\",\"2024-01-05\",\"Completed\"),\n",
        "    (\"ORD002\",\"C002\",\"Mumbai\",\"Electronics\",\"Mobile \",\"32000\",\"05/01/2024\",\"Completed\"),\n",
        "    (\"ORD003\",\"C003\",\"Bangalore\",\"Electronics\",\"Tablet\",\"30000\",\"2024/01/06\",\"Completed\"),\n",
        "    (\"ORD004\",\"C004\",\"Delhi\",\"Electronics\",\"Laptop\",\"\",\"2024-01-07\",\"Cancelled\"),\n",
        "    (\"ORD005\",\"C005\",\"Chennai\",\"Electronics\",\"Mobile\",\"invalid\",\"2024-01-08\",\"Completed\"),\n",
        "    (\"ORD006\",\"C006\",\"Mumbai\",\"Home\",\"Mixer\",None,\"2024-01-08\",\"Completed\"),\n",
        "    (\"ORD007\",\"C001\",\"Delhi\",\"Electronics\",\"Laptop\",\"47000\",\"09-01-2024\",\"Completed\"),\n",
        "    (\"ORD008\",\"C007\",\"Bangalore\",\"Home\",\"Vacuum\",\"28000\",\"2024-01-09\",\"Completed\"),\n",
        "    (\"ORD009\",\"C002\",\"Mumbai\",\"Electronics\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\"),\n",
        "    (\"ORD010\",\"C008\",\"Delhi\",\"Home\",\"AirPurifier\",\"38000\",\"2024-01-10\",\"Completed\"),\n",
        "    (\"ORD011\",\"C009\",\"Mumbai\",\"Home\",\"Vacuum\",\"29000\",\"2024-01-11\",\"Completed\"),\n",
        "    (\"ORD012\",\"C010\",\"Bangalore\",\"Electronics\",\"Mobile\",\"33000\",\"2024-01-11\",\"Completed\"),\n",
        "    (\"ORD013\",\"C003\",\"Bangalore\",\"Home\",\"Mixer\",\"21000\",\"2024-01-12\",\"Completed\"),\n",
        "    (\"ORD014\",\"C004\",\"Delhi\",\"Electronics\",\"Tablet\",\"26000\",\"2024-01-12\",\"Completed\"),\n",
        "    (\"ORD015\",\"C005\",\"Chennai\",\"Electronics\",\"Laptop\",\"62000\",\"2024-01-13\",\"Completed\"),\n",
        "    (\"ORD016\",\"C006\",\"Mumbai\",\"Home\",\"AirPurifier\",\"40000\",\"2024-01-13\",\"Completed\"),\n",
        "    (\"ORD017\",\"C007\",\"Bangalore\",\"Electronics\",\"Laptop\",\"51000\",\"2024-01-14\",\"Completed\"),\n",
        "    (\"ORD018\",\"C008\",\"Delhi\",\"Home\",\"Vacuum\",\"31000\",\"2024-01-14\",\"Completed\"),\n",
        "    (\"ORD019\",\"C009\",\"Mumbai\",\"Electronics\",\"Tablet\",\"29000\",\"2024-01-15\",\"Completed\"),\n",
        "    (\"ORD020\",\"C010\",\"Bangalore\",\"Electronics\",\"Laptop\",\"54000\",\"2024-01-15\",\"Completed\"),\n",
        "    (\"ORD020\",\"C010\",\"Bangalore\",\"Electronics\",\"Laptop\",\"54000\",\"2024-01-15\",\"Completed\")\n",
        "]\n"
      ],
      "metadata": {
        "id": "WWlZ-gvWy0bz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data"
      ],
      "metadata": {
        "id": "G8nhaaeP0Qvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType"
      ],
      "metadata": {
        "id": "xwPrHRJs0S8N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(orders_data, columns=[\n",
        "    \"OrderID\",\"CustomerID\",\"City\",\"Category\",\"Product\",\"Amount\",\"OrderDate\",\"Status\"\n",
        "])"
      ],
      "metadata": {
        "id": "0NK1545R0XI0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wxjV0N50vko",
        "outputId": "20a4c56e-62a0-40be-fc32-a506a8f10c92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-242626680.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Amount\"] = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")"
      ],
      "metadata": {
        "id": "V0845chd02bb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Amount\"].fillna(df[\"Amount\"].median(), inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97nj0ynH1CSG",
        "outputId": "e5a46e03-a733-4725-c3c5-af078cfd8ce9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3532854038.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Amount\"].fillna(df[\"Amount\"].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[\"Amount\"] = df[\"Amount\"].astype(int)"
      ],
      "metadata": {
        "id": "F4WH0gKc4Xdj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"OrderDate\"] = pd.to_datetime(df[\"OrderDate\"], errors=\"coerce\", dayfirst=True)"
      ],
      "metadata": {
        "id": "ygZiAgGr1HfO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "VzEWSlFY1MMi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"OrderID\", StringType(), True),\n",
        "    StructField(\"CustomerID\", StringType(), True),\n",
        "    StructField(\"City\", StringType(), True),\n",
        "    StructField(\"Category\", StringType(), True),\n",
        "    StructField(\"Product\", StringType(), True),\n",
        "    StructField(\"Amount\", IntegerType(), True),\n",
        "    StructField(\"OrderDate\", DateType(), True),\n",
        "    StructField(\"Status\", StringType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "B6ltBpkI1ThY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = spark.createDataFrame(df, schema=schema)"
      ],
      "metadata": {
        "id": "TGZutuYh1Zht"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K4Zh5WZ4cwm",
        "outputId": "ef7202e3-4750-41f7-fa96-5eb38d4faa6d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+-----------+------+----------+---------+\n",
            "|OrderID|CustomerID|     City|   Category|    Product|Amount| OrderDate|   Status|\n",
            "+-------+----------+---------+-----------+-----------+------+----------+---------+\n",
            "| ORD001|      C001|    Delhi|Electronics|     Laptop| 45000|2024-05-01|Completed|\n",
            "| ORD002|      C002|   Mumbai|Electronics|     Mobile| 32000|      NULL|Completed|\n",
            "| ORD003|      C003|Bangalore|Electronics|     Tablet| 30000|      NULL|Completed|\n",
            "| ORD004|      C004|    Delhi|Electronics|     Laptop| 35500|2024-07-01|Cancelled|\n",
            "| ORD005|      C005|  Chennai|Electronics|     Mobile| 35500|2024-08-01|Completed|\n",
            "| ORD006|      C006|   Mumbai|       Home|      Mixer| 35500|2024-08-01|Completed|\n",
            "| ORD007|      C001|    Delhi|Electronics|     Laptop| 47000|      NULL|Completed|\n",
            "| ORD008|      C007|Bangalore|       Home|     Vacuum| 28000|2024-09-01|Completed|\n",
            "| ORD009|      C002|   Mumbai|Electronics|     Laptop| 55000|2024-10-01|Completed|\n",
            "| ORD010|      C008|    Delhi|       Home|AirPurifier| 38000|2024-10-01|Completed|\n",
            "| ORD011|      C009|   Mumbai|       Home|     Vacuum| 29000|2024-11-01|Completed|\n",
            "| ORD012|      C010|Bangalore|Electronics|     Mobile| 33000|2024-11-01|Completed|\n",
            "| ORD013|      C003|Bangalore|       Home|      Mixer| 21000|2024-12-01|Completed|\n",
            "| ORD014|      C004|    Delhi|Electronics|     Tablet| 26000|2024-12-01|Completed|\n",
            "| ORD015|      C005|  Chennai|Electronics|     Laptop| 62000|      NULL|Completed|\n",
            "| ORD016|      C006|   Mumbai|       Home|AirPurifier| 40000|      NULL|Completed|\n",
            "| ORD017|      C007|Bangalore|Electronics|     Laptop| 51000|      NULL|Completed|\n",
            "| ORD018|      C008|    Delhi|       Home|     Vacuum| 31000|      NULL|Completed|\n",
            "| ORD019|      C009|   Mumbai|Electronics|     Tablet| 29000|      NULL|Completed|\n",
            "| ORD020|      C010|Bangalore|Electronics|     Laptop| 54000|      NULL|Completed|\n",
            "+-------+----------+---------+-----------+-----------+------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keep Only Completed Orders"
      ],
      "metadata": {
        "id": "Rmo9xqhgAkMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"Status\"] == \"Completed\"]"
      ],
      "metadata": {
        "id": "ICXSqUqiAjhd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verify No Nulls in Key Columns"
      ],
      "metadata": {
        "id": "mws5s8qIArPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_check = df[[\"OrderID\", \"Amount\", \"OrderDate\"]].isnull().sum()\n",
        "print(\"Null check:\\n\", null_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KyAuUdKAzd3",
        "outputId": "972e6e3a-f263-4ff9-b096-93520319ed60"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null check:\n",
            " OrderID      0\n",
            "Amount       0\n",
            "OrderDate    9\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = spark_df.dropna(subset=[\"OrderDate\"])"
      ],
      "metadata": {
        "id": "8UVVcEv0BDwG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_check = df[[\"OrderID\", \"Amount\", \"OrderDate\"]].isnull().sum()\n",
        "print(\"Null check:\\n\", null_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oxOf_S1BGLv",
        "outputId": "559abdba-0211-4f13-9740-c61a5c7e10c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null check:\n",
            " OrderID      0\n",
            "Amount       0\n",
            "OrderDate    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total Revenue per City\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d_e44ATlBpmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "revenue_city = spark_df.groupBy(\"City\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "revenue_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti7TTv97BxcA",
        "outputId": "e366eff7-e5aa-440e-fbf8-cbca3a65dc10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "|     City|TotalRevenue|\n",
            "+---------+------------+\n",
            "|Bangalore|       82000|\n",
            "|  Chennai|       35500|\n",
            "|   Mumbai|      119500|\n",
            "|    Delhi|      144500|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total revenue per category"
      ],
      "metadata": {
        "id": "BM18yix7B1uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_category = spark_df.groupBy(\"Category\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "revenue_category.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PJ9NCA6B4V2",
        "outputId": "6a34347d-b1c2-4595-ae64-19b041cb70d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|   Category|TotalRevenue|\n",
            "+-----------+------------+\n",
            "|       Home|      151500|\n",
            "|Electronics|      230000|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total Revenue per Product\n"
      ],
      "metadata": {
        "id": "pDvtLQX5CCcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_product = spark_df.groupBy(\"Product\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "revenue_product.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDJ6IVR3CHfN",
        "outputId": "1781b236-e04c-48cb-b00b-3420c9a7b68a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|    Product|TotalRevenue|\n",
            "+-----------+------------+\n",
            "|     Vacuum|       57000|\n",
            "|AirPurifier|       38000|\n",
            "|     Laptop|      135500|\n",
            "|      Mixer|       56500|\n",
            "|     Mobile|       68500|\n",
            "|     Tablet|       26000|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average Order Value per City"
      ],
      "metadata": {
        "id": "dn1aVMq2CjXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "avg_order_city = spark_df.groupBy(\"City\").agg(F.avg(\"Amount\").alias(\"AvgOrderValue\"))\n",
        "avg_order_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Aks59sFCkYK",
        "outputId": "7ee0d503-1d0c-480d-a984-2123e3b7f2c4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+\n",
            "|     City|     AvgOrderValue|\n",
            "+---------+------------------+\n",
            "|Bangalore|27333.333333333332|\n",
            "|  Chennai|           35500.0|\n",
            "|   Mumbai|39833.333333333336|\n",
            "|    Delhi|           36125.0|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify Top 3 Products by Revenue\n"
      ],
      "metadata": {
        "id": "m0Uaz_VlCqnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_products = (spark_df.groupBy(\"Product\")\n",
        "                .agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "                .orderBy(F.desc(\"TotalRevenue\"))\n",
        "                .limit(3))\n",
        "top_products.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkH_9z6TCvJC",
        "outputId": "bed0cbd6-9292-4365-e53d-7d604bbb455b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+\n",
            "|Product|TotalRevenue|\n",
            "+-------+------------+\n",
            "| Laptop|      135500|\n",
            "| Mobile|       68500|\n",
            "| Vacuum|       57000|\n",
            "+-------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Windows"
      ],
      "metadata": {
        "id": "ssxaqU7WEcxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "rUlQzdZTEiIP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rank Cities by Total Revenue"
      ],
      "metadata": {
        "id": "3s0nXKo2Ef_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_revenue = spark_df.groupBy(\"City\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "\n",
        "city_window = Window.orderBy(F.desc(\"TotalRevenue\"))\n",
        "\n",
        "ranked_cities = city_revenue.withColumn(\"Rank\", F.rank().over(city_window))\n",
        "ranked_cities.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOG8dwpjEmhP",
        "outputId": "4561ea7d-dfba-4edd-fa1d-cfa3dc49c682"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+----+\n",
            "|     City|TotalRevenue|Rank|\n",
            "+---------+------------+----+\n",
            "|    Delhi|      144500|   1|\n",
            "|   Mumbai|      119500|   2|\n",
            "|Bangalore|       82000|   3|\n",
            "|  Chennai|       35500|   4|\n",
            "+---------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rank Products Within Each Category by Revenue"
      ],
      "metadata": {
        "id": "x47qQ2PiEs1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_revenue = spark_df.groupBy(\"Category\",\"Product\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "\n",
        "product_window = Window.partitionBy(\"Category\").orderBy(F.desc(\"TotalRevenue\"))\n",
        "\n",
        "ranked_products = product_revenue.withColumn(\"Rank\", F.dense_rank().over(product_window))\n",
        "ranked_products.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mGlxuKCEwZJ",
        "outputId": "88abde7a-d88e-497c-eaeb-f457a8468782"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+----+\n",
            "|   Category|    Product|TotalRevenue|Rank|\n",
            "+-----------+-----------+------------+----+\n",
            "|Electronics|     Laptop|      135500|   1|\n",
            "|Electronics|     Mobile|       68500|   2|\n",
            "|Electronics|     Tablet|       26000|   3|\n",
            "|       Home|     Vacuum|       57000|   1|\n",
            "|       Home|      Mixer|       56500|   2|\n",
            "|       Home|AirPurifier|       38000|   3|\n",
            "+-----------+-----------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cache"
      ],
      "metadata": {
        "id": "K-UGIlJQE3qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.cache()\n",
        "spark_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63L5faRdFLCq",
        "outputId": "a8936797-8561-4ad3-b2f1-1d288dbb6293"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Multiple Aggregations and Observe Behavior"
      ],
      "metadata": {
        "id": "mTjvUoVdFQ5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_city = spark_df.groupBy(\"City\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "revenue_category = spark_df.groupBy(\"Category\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "avg_order_city = spark_df.groupBy(\"City\").agg(F.avg(\"Amount\").alias(\"AvgOrderValue\"))\n",
        "\n",
        "revenue_city.show()\n",
        "revenue_category.show()\n",
        "avg_order_city.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joeh6qJHFUZ6",
        "outputId": "457a1723-81cc-44e2-b25b-305cb3dab352"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "|     City|TotalRevenue|\n",
            "+---------+------------+\n",
            "|Bangalore|       82000|\n",
            "|  Chennai|       35500|\n",
            "|   Mumbai|      119500|\n",
            "|    Delhi|      144500|\n",
            "+---------+------------+\n",
            "\n",
            "+-----------+------------+\n",
            "|   Category|TotalRevenue|\n",
            "+-----------+------------+\n",
            "|       Home|      151500|\n",
            "|Electronics|      230000|\n",
            "+-----------+------------+\n",
            "\n",
            "+---------+------------------+\n",
            "|     City|     AvgOrderValue|\n",
            "+---------+------------------+\n",
            "|Bangalore|27333.333333333332|\n",
            "|  Chennai|           35500.0|\n",
            "|   Mumbai|39833.333333333336|\n",
            "|    Delhi|           36125.0|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explain"
      ],
      "metadata": {
        "id": "Z9ctRJL4FbZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_city.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PplC8HB-Fd6c",
        "outputId": "426f473e-2f1b-4dd0-e5d2-36b1b9093aa1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['City], ['City, 'sum('Amount) AS TotalRevenue#457]\n",
            "+- Filter atleastnnonnulls(1, OrderDate#6)\n",
            "   +- LogicalRDD [OrderID#0, CustomerID#1, City#2, Category#3, Product#4, Amount#5, OrderDate#6, Status#7], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "City: string, TotalRevenue: bigint\n",
            "Aggregate [City#2], [City#2, sum(Amount#5) AS TotalRevenue#457L]\n",
            "+- Filter atleastnnonnulls(1, OrderDate#6)\n",
            "   +- LogicalRDD [OrderID#0, CustomerID#1, City#2, Category#3, Product#4, Amount#5, OrderDate#6, Status#7], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [City#2], [City#2, sum(Amount#5) AS TotalRevenue#457L]\n",
            "+- Project [City#2, Amount#5]\n",
            "   +- InMemoryRelation [OrderID#0, CustomerID#1, City#2, Category#3, Product#4, Amount#5, OrderDate#6, Status#7], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "         +- *(1) Filter atleastnnonnulls(1, OrderDate#6)\n",
            "            +- *(1) Scan ExistingRDD[OrderID#0,CustomerID#1,City#2,Category#3,Product#4,Amount#5,OrderDate#6,Status#7]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[City#2], functions=[sum(Amount#5)], output=[City#2, TotalRevenue#457L])\n",
            "   +- Exchange hashpartitioning(City#2, 200), ENSURE_REQUIREMENTS, [plan_id=709]\n",
            "      +- HashAggregate(keys=[City#2], functions=[partial_sum(Amount#5)], output=[City#2, sum#610L])\n",
            "         +- InMemoryTableScan [City#2, Amount#5]\n",
            "               +- InMemoryRelation [OrderID#0, CustomerID#1, City#2, Category#3, Product#4, Amount#5, OrderDate#6, Status#7], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- *(1) Filter atleastnnonnulls(1, OrderDate#6)\n",
            "                        +- *(1) Scan ExistingRDD[OrderID#0,CustomerID#1,City#2,Category#3,Product#4,Amount#5,OrderDate#6,Status#7]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write cleaned order-level data to Parquet"
      ],
      "metadata": {
        "id": "kFbXpvzuF6PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.write.mode(\"overwrite\").parquet(\"output/cleaned_orders_parquet\")"
      ],
      "metadata": {
        "id": "NWPlXPEdF7g1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ORC"
      ],
      "metadata": {
        "id": "xImW3jkwGBIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "revenue_city = spark_df.groupBy(\"City\").agg(F.sum(\"Amount\").alias(\"TotalRevenue\"))\n",
        "revenue_city.write.mode(\"overwrite\").orc(\"output/revenue_city_orc\")"
      ],
      "metadata": {
        "id": "1pIRzTaJGFpe"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "habdphCsBHvx"
      }
    }
  ]
}