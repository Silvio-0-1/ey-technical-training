{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrFBuB6AD1YNmB5WGZet4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Silvio-0-1/ey-technical-training/blob/main/Telecom_Network_Quality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TelecomNetworkQuality\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "u4ny2H-YZ-rf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import trim, col, when, to_date, sum as spark_sum, avg, desc, rank, lit, coalesce, isnull,try_to_timestamp,regexp_extract,initcap"
      ],
      "metadata": {
        "id": "RJ9GPGuuZ7ZC"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PHASE 1: INGESTION**\n"
      ],
      "metadata": {
        "id": "o4Cd_CtKatKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Read network_logs.csv as all StringType\n",
        "schema_string = StructType([\n",
        "    StructField(\"event_id\", StringType(), True),\n",
        "    StructField(\"subscriber_id\", StringType(), True),\n",
        "    StructField(\"tower_id\", StringType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"network_type\", StringType(), True),\n",
        "    StructField(\"signal_strength\", StringType(), True),\n",
        "    StructField(\"download_speed_mbps\", StringType(), True),\n",
        "    StructField(\"upload_speed_mbps\", StringType(), True),\n",
        "    StructField(\"latency_ms\", StringType(), True),\n",
        "    StructField(\"call_drop\", StringType(), True),\n",
        "    StructField(\"event_time\", StringType()),\n",
        "    StructField(\"device_type\", StringType(), True)\n",
        "])\n",
        "\n",
        "df_raw = spark.read.csv(\"/content/network_logs.csv\", header=True, schema=schema_string)"
      ],
      "metadata": {
        "id": "xSiWHEqfbJOy"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Print schema and row count\n",
        "df_raw.printSchema()\n",
        "print(f\"Raw Row Count: {df_raw.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nlwkKPWbQZO",
        "outputId": "f733bb57-827d-4537-ea9e-607da0b40d5d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- subscriber_id: string (nullable = true)\n",
            " |-- tower_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- network_type: string (nullable = true)\n",
            " |-- signal_strength: string (nullable = true)\n",
            " |-- download_speed_mbps: string (nullable = true)\n",
            " |-- upload_speed_mbps: string (nullable = true)\n",
            " |-- latency_ms: string (nullable = true)\n",
            " |-- call_drop: string (nullable = true)\n",
            " |-- event_time: string (nullable = true)\n",
            " |-- device_type: string (nullable = true)\n",
            "\n",
            "Raw Row Count: 180000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Show sample rows\n",
        "df_raw.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j7UynEybUSy",
        "outputId": "49be51d2-98c0-4fb2-825a-bc5aef80c266"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "|event_id|subscriber_id|tower_id|     city|network_type|signal_strength|download_speed_mbps|upload_speed_mbps|latency_ms|call_drop|         event_time| device_type|\n",
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "| E100000|        S5975|    T837|Bangalore|          3G|        invalid|               NULL|             NULL|   invalid|      YES|01/01/2026 00:00:00|     Android|\n",
            "| E100001|        S3537|    T283|Hyderabad|          5G|            -83|             124.07|            41.26|       114|       NO|2026-01-01 00:00:03|FeaturePhone|\n",
            "| E100002|        S1629|    T877|     Pune|          4G|            -72|              41.01|             3.36|       221|       NO|2026-01-01 00:00:06|FeaturePhone|\n",
            "| E100003|        S9422|    T431|    Delhi|          3G|            -97|              46.98|            13.36|       148|       NO|2026-01-01 00:00:09|     Android|\n",
            "| E100004|        S1776|    T432|Hyderabad|          3G|            -83|               15.3|             31.1|       251|       NO|2026-01-01 00:00:12|FeaturePhone|\n",
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PHASE 2: CLEANING**"
      ],
      "metadata": {
        "id": "gyBQJeKxbV-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Trim string columns\n",
        "df_trimmed = df_raw.select([F.trim(F.col(c)).alias(c) for c in df_raw.columns])\n",
        "\n",
        "df_trimmed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvteQ8RWbkXy",
        "outputId": "ed1191d0-3362-4c84-836a-c98da5e29800"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "|event_id|subscriber_id|tower_id|     city|network_type|signal_strength|download_speed_mbps|upload_speed_mbps|latency_ms|call_drop|         event_time| device_type|\n",
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "| E100000|        S5975|    T837|Bangalore|          3G|        invalid|               NULL|             NULL|   invalid|      YES|01/01/2026 00:00:00|     Android|\n",
            "| E100001|        S3537|    T283|Hyderabad|          5G|            -83|             124.07|            41.26|       114|       NO|2026-01-01 00:00:03|FeaturePhone|\n",
            "| E100002|        S1629|    T877|     Pune|          4G|            -72|              41.01|             3.36|       221|       NO|2026-01-01 00:00:06|FeaturePhone|\n",
            "| E100003|        S9422|    T431|    Delhi|          3G|            -97|              46.98|            13.36|       148|       NO|2026-01-01 00:00:09|     Android|\n",
            "| E100004|        S1776|    T432|Hyderabad|          3G|            -83|               15.3|             31.1|       251|       NO|2026-01-01 00:00:12|FeaturePhone|\n",
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Normalize string fields (city, network_type, device_type, call_drop)\n",
        "df_normalized = df_trimmed \\\n",
        "    .withColumn(\"city\", F.lower(F.col(\"city\"))) \\\n",
        "    .withColumn(\"network_type\", F.upper(F.col(\"network_type\"))) \\\n",
        "    .withColumn(\"device_type\", F.lower(F.col(\"device_type\"))) \\\n",
        "    .withColumn(\"call_drop\", F.upper(F.col(\"call_drop\")))\n",
        "\n",
        "df_normalized.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPc8oDGdbpWq",
        "outputId": "a3a867b1-be5e-43df-97fc-e6932d7df7f3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "|event_id|subscriber_id|tower_id|     city|network_type|signal_strength|download_speed_mbps|upload_speed_mbps|latency_ms|call_drop|         event_time| device_type|\n",
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "| E100000|        S5975|    T837|bangalore|          3G|        invalid|               NULL|             NULL|   invalid|      YES|01/01/2026 00:00:00|     android|\n",
            "| E100001|        S3537|    T283|hyderabad|          5G|            -83|             124.07|            41.26|       114|       NO|2026-01-01 00:00:03|featurephone|\n",
            "| E100002|        S1629|    T877|     pune|          4G|            -72|              41.01|             3.36|       221|       NO|2026-01-01 00:00:06|featurephone|\n",
            "| E100003|        S9422|    T431|    delhi|          3G|            -97|              46.98|            13.36|       148|       NO|2026-01-01 00:00:09|     android|\n",
            "| E100004|        S1776|    T432|hyderabad|          3G|            -83|               15.3|             31.1|       251|       NO|2026-01-01 00:00:12|featurephone|\n",
            "+--------+-------------+--------+---------+------------+---------------+-------------------+-----------------+----------+---------+-------------------+------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Clean numeric fields safely (Invalid values become null)\n",
        "df_cleaned = df_normalized \\\n",
        "    .withColumn(\"signal_strength_clean\", F.col(\"signal_strength\").cast(IntegerType())) \\\n",
        "    .withColumn(\"download_speed_clean\", F.col(\"download_speed_mbps\").cast(DoubleType())) \\\n",
        "    .withColumn(\"upload_speed_clean\", F.col(\"upload_speed_mbps\").cast(DoubleType())) \\\n",
        "    .withColumn(\"latency_clean\", F.col(\"latency_ms\").cast(IntegerType()))\n",
        "\n",
        "df_cleaned.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNkTWETejMPI",
        "outputId": "f382beff-3235-4c48-b2df-3d315e4c86a3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- event_id: string (nullable = true)\n",
            " |-- subscriber_id: string (nullable = true)\n",
            " |-- tower_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- network_type: string (nullable = true)\n",
            " |-- signal_strength: string (nullable = true)\n",
            " |-- download_speed_mbps: string (nullable = true)\n",
            " |-- upload_speed_mbps: string (nullable = true)\n",
            " |-- latency_ms: string (nullable = true)\n",
            " |-- call_drop: string (nullable = true)\n",
            " |-- event_time: string (nullable = true)\n",
            " |-- device_type: string (nullable = true)\n",
            " |-- signal_strength_clean: integer (nullable = true)\n",
            " |-- download_speed_clean: double (nullable = true)\n",
            " |-- upload_speed_clean: double (nullable = true)\n",
            " |-- latency_clean: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF-LBbDTo9OT",
        "outputId": "9bf6f6e0-9392-49d7-9536-ba4fa21909a8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, event_id: string, subscriber_id: string, tower_id: string, city: string, network_type: string, signal_strength: string, download_speed_mbps: string, upload_speed_mbps: string, latency_ms: string, call_drop: string, event_time: string, device_type: string, signal_strength_clean: string, download_speed_clean: string, upload_speed_clean: string, latency_clean: string]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import expr, coalesce\n",
        "\n",
        "df_cleaned_date = df_cleaned.withColumn(\n",
        "    \"event_time_new\",\n",
        "    coalesce(\n",
        "        expr(to_date(try_to_timestamp(col(\"event_time\"), 'yyyy-MM-dd'))),\n",
        "        expr(to_date(try_to_timestamp(col(\"event_time\"), 'dd/MM/yyyy'))),\n",
        "        expr(to_date(try_to_timestamp(col(\"event_time\"), 'yyyy/MM/dd')))\n",
        "    )\n",
        ")\n",
        "\n",
        "df_cleaned_date.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "BH7f-j_2jMqF",
        "outputId": "86c7f7aa-07b1-4965-deb1-0ca83fc9ca2d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PySparkTypeError",
          "evalue": "[NOT_ITERABLE] Column is not iterable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2153896641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"event_time_new\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     coalesce(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_to_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"event_time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yyyy-MM-dd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_to_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"event_time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dd/MM/yyyy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_to_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"event_time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yyyy/MM/dd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFuncT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/functions/builtin.py\u001b[0m in \u001b[0;36mexpr\u001b[0;34m(str)\u001b[0m\n\u001b[1;32m   8095\u001b[0m     \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8096\u001b[0m     \"\"\"\n\u001b[0;32m-> 8097\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_invoke_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/functions/builtin.py\u001b[0m in \u001b[0;36m_invoke_function\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mjf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_jvm_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                         \u001b[0mtemp_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mArrayList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJavaClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"java.util.ArrayList\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mjava_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/column.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         raise PySparkTypeError(\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0merrorClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NOT_ITERABLE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessageParameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"objectName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Column\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         )\n",
            "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_ITERABLE] Column is not iterable."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PHASE 3: VALIDATION**"
      ],
      "metadata": {
        "id": "O2r1SGjBcPlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Count invalid values for each numeric field (where result is null but original wasn't null/empty)\n",
        "# 2. Count invalid timestamps\n",
        "invalid_counts = df_cleaned.select(\n",
        "    F.sum(F.when(F.col(\"signal_strength_clean\").isNull() & F.col(\"signal_strength\").isNotNull(), 1).otherwise(0)).alias(\"invalid_signal\"),\n",
        "    F.sum(F.when(F.col(\"download_speed_clean\").isNull() & F.col(\"download_speed_mbps\").isNotNull(), 1).otherwise(0)).alias(\"invalid_download\"),\n",
        "    F.sum(F.when(F.col(\"upload_speed_clean\").isNull() & F.col(\"upload_speed_mbps\").isNotNull(), 1).otherwise(0)).alias(\"invalid_upload\"),\n",
        "    F.sum(F.when(F.col(\"latency_clean\").isNull() & F.col(\"latency_ms\").isNotNull(), 1).otherwise(0)).alias(\"invalid_latency\"),\n",
        "    F.sum(F.when(F.col(\"event_time_clean\").isNull() & F.col(\"event_time\").isNotNull(), 1).otherwise(0)).alias(\"invalid_time\")\n",
        ")\n",
        "print(\"Invalid Value Counts:\")\n",
        "invalid_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "wu9Z51iWcOrd",
        "outputId": "670be874-ad55-4523-9974-cc2fd1f8eb88"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid Value Counts:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"ts\": \"2026-01-19 09:13:15.362\", \"level\": \"ERROR\", \"logger\": \"DataFrameQueryContextLogger\", \"msg\": \"[CAST_INVALID_INPUT] The value 'invalid' of the type \\\"STRING\\\" cannot be cast to \\\"INT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\", \"context\": {\"file\": \"line 4 in cell [29]\", \"line\": \"\", \"fragment\": \"cast\", \"errorClass\": \"CAST_INVALID_INPUT\"}, \"exception\": {\"class\": \"Py4JJavaError\", \"msg\": \"An error occurred while calling o880.showString.\\n: org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value 'invalid' of the type \\\"STRING\\\" cannot be cast to \\\"INT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\\n== DataFrame ==\\n\\\"cast\\\" was called from\\nline 4 in cell [29]\\n\\n\\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toIntExact(UTF8StringUtils.scala:34)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toIntExact(UTF8StringUtils.scala)\\n\\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\\n\\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithoutKey_0$(Unknown Source)\\n\\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\\n\\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\\n\\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\\n\\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\\n\\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\\n\\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\", \"stacktrace\": [{\"class\": null, \"method\": \"deco\", \"file\": \"/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\", \"line\": \"282\"}, {\"class\": null, \"method\": \"get_return_value\", \"file\": \"/usr/local/lib/python3.12/dist-packages/py4j/protocol.py\", \"line\": \"327\"}]}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NumberFormatException",
          "evalue": "[CAST_INVALID_INPUT] The value 'invalid' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"cast\" was called from\nline 4 in cell [29]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNumberFormatException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1796730012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Value Counts:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0minvalid_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     def _show_string(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36m_show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNumberFormatException\u001b[0m: [CAST_INVALID_INPUT] The value 'invalid' of the type \"STRING\" cannot be cast to \"INT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"cast\" was called from\nline 4 in cell [29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Remove duplicate logs based on event_id\n",
        "df_deduped = df_cleaned.dropDuplicates([\"event_id\"])\n",
        "print(f\"Count after deduplication: {df_deduped.count()}\")"
      ],
      "metadata": {
        "id": "TaditZZfcgvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PHASE 4: NETWORK KPIS**"
      ],
      "metadata": {
        "id": "capJDdGicks8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: Create a numeric flag for call drop for easy averaging\n",
        "df_kpi_base = df_deduped.withColumn(\"is_call_drop\", F.when(F.col(\"call_drop\") == \"YES\", 1).otherwise(0))\n",
        "\n",
        "# 1. Average download speed per city\n",
        "# 2. Average latency per city\n",
        "# 3. Call drop rate per city\n",
        "city_kpis = df_kpi_base.groupBy(\"city\").agg(\n",
        "    F.avg(\"download_speed_clean\").alias(\"avg_download_speed\"),\n",
        "    F.avg(\"latency_clean\").alias(\"avg_latency\"),\n",
        "    (F.sum(\"is_call_drop\") / F.count(\"*\")).alias(\"call_drop_rate\")\n",
        ")\n",
        "print(\"KPIs per City:\")\n",
        "city_kpis.show()"
      ],
      "metadata": {
        "id": "q_A7Q3XHdhuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Call drop rate per tower\n",
        "tower_kpis = df_kpi_base.groupBy(\"tower_id\", \"city\").agg(\n",
        "    F.avg(\"download_speed_clean\").alias(\"avg_download_speed\"),\n",
        "    F.avg(\"latency_clean\").alias(\"avg_latency\"),\n",
        "    (F.sum(\"is_call_drop\") / F.count(\"*\")).alias(\"call_drop_rate\")\n",
        ")"
      ],
      "metadata": {
        "id": "sPjA2rvwdjfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Identify top 10 worst towers\n",
        "# Criteria: High Drop Rate, High Latency, Low Download Speed\n",
        "# We can order by these columns descending/ascending respectively.\n",
        "worst_towers = tower_kpis.orderBy(\n",
        "    F.desc(\"call_drop_rate\"),\n",
        "    F.desc(\"avg_latency\"),\n",
        "    F.asc(\"avg_download_speed\")\n",
        ").limit(10)\n",
        "\n",
        "print(\"Top 10 Worst Towers:\")\n",
        "worst_towers.show()"
      ],
      "metadata": {
        "id": "x6accqgTc2h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PHASE 5: CUSTOMER EXPERIENCE**"
      ],
      "metadata": {
        "id": "sIUgNFkmc6Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics for each subscriber_id\n",
        "subscriber_stats = df_kpi_base.groupBy(\"subscriber_id\").agg(\n",
        "    F.count(\"event_id\").alias(\"total_events\"),\n",
        "    F.avg(\"download_speed_clean\").alias(\"sub_avg_download\"),\n",
        "    F.avg(\"latency_clean\").alias(\"sub_avg_latency\"),\n",
        "    F.sum(\"is_call_drop\").alias(\"call_drop_count\")\n",
        ")\n",
        "\n",
        "# 5. Identify subscribers with poor experience\n",
        "# Logic defined: High drops (>3), Low speed (<5 Mbps), OR High latency (>100ms) - Example thresholds\n",
        "poor_experience_subs = subscriber_stats.filter(\n",
        "    (F.col(\"call_drop_count\") > 3) |\n",
        "    (F.col(\"sub_avg_download\") < 5.0) |\n",
        "    (F.col(\"sub_avg_latency\") > 100)\n",
        ")\n",
        "\n",
        "print(\"Sample Subscribers with Poor Experience:\")\n",
        "poor_experience_subs.show(5)"
      ],
      "metadata": {
        "id": "v6Uh4IHmc4e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PHASE 6: WINDOW FUNCTIONS**"
      ],
      "metadata": {
        "id": "zpx2DVbPdJJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Rank towers within each city by call drop rate\n",
        "window_city_tower = Window.partitionBy(\"city\").orderBy(F.desc(\"call_drop_rate\"))\n",
        "\n",
        "tower_ranks = tower_kpis.withColumn(\"rank_in_city\", F.rank().over(window_city_tower))\n",
        "print(\"Towers Ranked by Drop Rate (per City):\")\n",
        "tower_ranks.show(5)"
      ],
      "metadata": {
        "id": "LaqRGjkidoUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Rank subscribers within each city by worst experience\n",
        "# We need city info at subscriber level. Joining back or carrying city in aggregation.\n",
        "# For simplicity, let's assume we aggregate by subscriber AND city (assuming subs stay in one city mostly)\n",
        "sub_city_stats = df_kpi_base.groupBy(\"subscriber_id\", \"city\").agg(\n",
        "    F.sum(\"is_call_drop\").alias(\"call_drop_count\")\n",
        ")\n",
        "window_city_sub = Window.partitionBy(\"city\").orderBy(F.desc(\"call_drop_count\"))\n",
        "\n",
        "sub_ranks = sub_city_stats.withColumn(\"worst_exp_rank\", F.rank().over(window_city_sub))\n",
        "print(\"Subscribers Ranked by Worst Experience (per City):\")\n",
        "sub_ranks.show(5)"
      ],
      "metadata": {
        "id": "JpKxOgjDdp3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Use lag() to detect sudden deterioration in signal_strength for a tower\n",
        "# We need time-series data per tower\n",
        "window_tower_time = Window.partitionBy(\"tower_id\").orderBy(\"event_time_clean\")\n",
        "\n",
        "df_signal_lag = df_kpi_base.withColumn(\n",
        "    \"prev_signal\",\n",
        "    F.lag(\"signal_strength_clean\").over(window_tower_time)\n",
        ")\n",
        "\n",
        "# Detect if signal dropped by more than 10 dBm compared to previous log\n",
        "df_signal_deterioration = df_signal_lag.withColumn(\n",
        "    \"signal_drop\",\n",
        "    F.col(\"prev_signal\") - F.col(\"signal_strength_clean\")\n",
        ").filter(F.col(\"signal_drop\") > 10)\n",
        "\n",
        "print(\"Events with Sudden Signal Deterioration:\")\n",
        "df_signal_deterioration.select(\"tower_id\", \"event_time_clean\", \"signal_strength_clean\", \"prev_signal\", \"signal_drop\").show(5)"
      ],
      "metadata": {
        "id": "wMfZ1SX0dSPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PHASE 7: ANOMALY DETECTION**"
      ],
      "metadata": {
        "id": "dXkQKoAydXqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh1dhoKWZhXx"
      },
      "outputs": [],
      "source": [
        "# Detect towers where: Latency spikes, Download speed drops, Call drops spike\n",
        "# Using Window functions and LAG\n",
        "\n",
        "df_anomalies = df_kpi_base.withColumn(\n",
        "    \"prev_latency\", F.lag(\"latency_clean\").over(window_tower_time)\n",
        ").withColumn(\n",
        "    \"prev_speed\", F.lag(\"download_speed_clean\").over(window_tower_time)\n",
        ").withColumn(\n",
        "    \"prev_drops\", F.lag(\"is_call_drop\").over(window_tower_time) # lagging the binary flag\n",
        ")\n",
        "\n",
        "# Logic for Anomaly:\n",
        "# 1. Latency spikes: Current > 2x Previous\n",
        "# 2. Speed drops: Current < 0.5x Previous\n",
        "# 3. Call drops spike: Current is drop, previous was NOT drop (transition to failure)\n",
        "anomalous_events = df_anomalies.filter(\n",
        "    (F.col(\"latency_clean\") > 2 * F.col(\"prev_latency\")) |\n",
        "    (F.col(\"download_speed_clean\") < 0.5 * F.col(\"prev_speed\")) |\n",
        "    ((F.col(\"is_call_drop\") == 1) & (F.col(\"prev_drops\") == 0))\n",
        ")\n",
        "\n",
        "print(\"Anomalous Tower Events:\")\n",
        "anomalous_events.select(\"tower_id\", \"event_time_clean\", \"latency_clean\", \"prev_latency\", \"download_speed_clean\", \"is_call_drop\").show(5)"
      ]
    }
  ]
}