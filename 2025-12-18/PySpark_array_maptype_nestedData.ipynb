{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi7p05812taF",
        "outputId": "93c7178b-2b52-47c1-e700-a6657c70d3b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import ArrayType"
      ],
      "metadata": {
        "id": "5HkO37wzpFjM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MyApp\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "g1IQsXtmplw5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_data = [\n",
        "    (\"U001\",[\"AI\",\"ML\",\"Cloud\"]),\n",
        "    (\"U002\",[\"Testing\",\"Automation\"]),\n",
        "    (\"U003\",[\"Data Engineering\",\"Spark\",\"Kafka\"]),\n",
        "    (\"U004\",[\"UI/UX\"])\n",
        "]"
      ],
      "metadata": {
        "id": "uSZ25IZQpSdz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interest_schema=StructType([\n",
        "    StructField(\"user_id\", StringType(), False),\n",
        "    StructField(\"interests\", ArrayType(StringType()), True),\n",
        "])"
      ],
      "metadata": {
        "id": "3TjLN-jHrI6C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_interest=spark.createDataFrame(interest_data, interest_schema)\n",
        "df_interest.printSchema()\n",
        "df_interest.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC_N06wprZYY",
        "outputId": "223645e6-e104-4167-ca44-aedf5584011a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- interests: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+--------------------------------+\n",
            "|user_id|interests                       |\n",
            "+-------+--------------------------------+\n",
            "|U001   |[AI, ML, Cloud]                 |\n",
            "|U002   |[Testing, Automation]           |\n",
            "|U003   |[Data Engineering, Spark, Kafka]|\n",
            "|U004   |[UI/UX]                         |\n",
            "+-------+--------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "df_interest.select(\n",
        "    \"user_id\",\n",
        "    explode(\"interests\").alias(\"interest\")\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAaHob3yr2lP",
        "outputId": "71a942a5-e61b-479a-fd02-4219357208b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+\n",
            "|user_id|        interest|\n",
            "+-------+----------------+\n",
            "|   U001|              AI|\n",
            "|   U001|              ML|\n",
            "|   U001|           Cloud|\n",
            "|   U002|         Testing|\n",
            "|   U002|      Automation|\n",
            "|   U003|Data Engineering|\n",
            "|   U003|           Spark|\n",
            "|   U003|           Kafka|\n",
            "|   U004|           UI/UX|\n",
            "+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MapType"
      ],
      "metadata": {
        "id": "_IXT_YDBsq9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import MapType"
      ],
      "metadata": {
        "id": "hv0Af7vosuP0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_data = [\n",
        "    (\"U001\",{\"mobile\":120,\"laptop\":300}),\n",
        "    (\"U002\",{\"tablet\":80}),\n",
        "    (\"U003\",{\"mobile\":200,\"desktop\":400}),\n",
        "    (\"U004\",{\"laptop\":250})\n",
        "]"
      ],
      "metadata": {
        "id": "Vmb0y8kgsy_h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_schema=StructType([\n",
        "    StructField(\"user_id\", StringType(), False),\n",
        "    StructField(\"device_usage\", MapType(StringType(), IntegerType()), True)\n",
        "])"
      ],
      "metadata": {
        "id": "zxxmDAUHs2cB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_devices=spark.createDataFrame(device_data, device_schema)\n",
        "df_devices.printSchema()\n",
        "df_devices.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ol2YGrPtTW1",
        "outputId": "1af0a02d-7439-44e2-8ff9-c401e3bf592f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- device_usage: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: integer (valueContainsNull = true)\n",
            "\n",
            "+-------+-------------------------------+\n",
            "|user_id|device_usage                   |\n",
            "+-------+-------------------------------+\n",
            "|U001   |{mobile -> 120, laptop -> 300} |\n",
            "|U002   |{tablet -> 80}                 |\n",
            "|U003   |{mobile -> 200, desktop -> 400}|\n",
            "|U004   |{laptop -> 250}                |\n",
            "+-------+-------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Nested Data"
      ],
      "metadata": {
        "id": "dlXmig2EuBdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nested_data = [\n",
        "\n",
        "    (\"U001\",(\"Hyderabad\",\"Telangana\",500081)),\n",
        "\n",
        "    (\"U002\",(\"Delhi\",\"Delhi\",110001)),\n",
        "\n",
        "    (\"U003\",(\"Bangalore\",\"Karnataka\",560001))\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "GLaVRsVbus4D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address_schema=StructType([\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"state\", StringType(), True),\n",
        "    StructField(\"pincode\", IntegerType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "YvmfxGFwuCm_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile_schema=StructType([\n",
        "    StructField(\"user_id\", StringType(), False),\n",
        "    StructField(\"address\", address_schema, True)\n",
        "])"
      ],
      "metadata": {
        "id": "uSWjQRIVuWU8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_profiles=spark.createDataFrame(nested_data, profile_schema)\n",
        "df_profiles.printSchema()\n",
        "df_profiles.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzEv5NFsu27e",
        "outputId": "3d98898d-9de9-4ef7-d9fc-665ff59fc667"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- state: string (nullable = true)\n",
            " |    |-- pincode: integer (nullable = true)\n",
            "\n",
            "+-------+------------------------------+\n",
            "|user_id|address                       |\n",
            "+-------+------------------------------+\n",
            "|U001   |{Hyderabad, Telangana, 500081}|\n",
            "|U002   |{Delhi, Delhi, 110001}        |\n",
            "|U003   |{Bangalore, Karnataka, 560001}|\n",
            "+-------+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select Specifics"
      ],
      "metadata": {
        "id": "GikRu5QkvwiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_profiles.select(\n",
        "    \"user_id\",\n",
        "    \"address.city\",\n",
        "    \"address.state\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqiKHQ6CvyvG",
        "outputId": "04e2d0f0-2831-4310-df8c-a5887f057990"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+\n",
            "|user_id|     city|    state|\n",
            "+-------+---------+---------+\n",
            "|   U001|Hyderabad|Telangana|\n",
            "|   U002|    Delhi|    Delhi|\n",
            "|   U003|Bangalore|Karnataka|\n",
            "+-------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Type Casting"
      ],
      "metadata": {
        "id": "1eRMVldVwHA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_users.withColumn(\n",
        "    'salary_int',\n",
        "    col(\"salary\").cast(\"int\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9KX85v0wF6V",
        "outputId": "84875fe4-3e9d-4060-b5b7-00d082d83726"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[user_id: string, name: string, age: int, city: string, salary: bigint, salary_int: int]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}